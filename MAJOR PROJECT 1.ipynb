{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13aca220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54cfcee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('disaster_tweets_data.csv',encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8b25da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['tweets','target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f16f35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweets'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "026c841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n"
     ]
    }
   ],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "sw = stopwords.words('English')\n",
    "print(sw[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca19dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deed reason earthquake may allah forgive u', 'forest fire near la ronge sask canada', 'resident asked shelter place notified officer evacuation shelter place order expected', '13 000 people receive wildfire evacuation order california', 'got sent photo ruby alaska smoke wildfire pours school']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in df['tweets'].iloc[:5]:\n",
    "    t = i.lower()                     # lower case conversion\n",
    "    t = re.sub('[^A-Za-z0-9]',' ',t)  # removing punc\n",
    "    t = word_tokenize(t)              # word tekenize\n",
    "    t = [i for i in t if i not in sw] # sw removal\n",
    "    t = [lm.lemmatize(i) for i in t]  # lemmatization\n",
    "    t = \" \".join(t)                   # joinig words to froms sentences\n",
    "    data.append(t)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0dfc309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in df['tweets']:\n",
    "    t = i.lower()                     # lower case conversion\n",
    "    t = re.sub('[^A-Za-z0-9]',' ',t)  # removing punc\n",
    "    t = word_tokenize(t)              # word tekenize\n",
    "    t = [i for i in t if i not in sw] # sw removal\n",
    "    t = [lm.lemmatize(i) for i in t]  # lemmatization\n",
    "    t = \" \".join(t)                   # joinig words to froms sentences\n",
    "    data.append(t)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff03131",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffbc6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.30,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "584bf2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5329, 1500)\n",
      "(2284, 1500)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=1500)\n",
    "\n",
    "x_train_cv = cv.fit_transform(x_train)\n",
    "x_test_cv = cv.transform(x_test)\n",
    "print(x_train_cv.shape)\n",
    "print(x_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "749e5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(ytest,ypred):\n",
    "    cm = confusion_matrix(ytest,ypred)\n",
    "    print('Accuracy: ',metrics.accuracy_score(y_test, ypred))\n",
    "    print(cm)\n",
    "    print(classification_report(ytest,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e0eb20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train_cv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe7d1331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.8239819853631075\n",
      "Test Score 0.7841506129597198\n"
     ]
    }
   ],
   "source": [
    "print('Train Score',mnb.score(x_train_cv,y_train))  # Train Acc\n",
    "print('Test Score',mnb.score(x_test_cv,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0cf3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_mnb = mnb.predict(x_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aaf8305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_cv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e2b4a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.8799024207168324\n",
      "Test Score 0.7981611208406305\n"
     ]
    }
   ],
   "source": [
    "print('Train Score',lr.score(x_train_cv,y_train))\n",
    "print('Test Score',lr.score(x_test_cv,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19bb41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_lr = lr.predict(x_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b5fd1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = KNeighborsClassifier(n_neighbors=11)\n",
    "m1.fit(x_train_cv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3778086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score 0.7547382248076562\n",
      "Test Score 0.7092819614711033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "print('Train Score',m1.score(x_train_cv,y_train)) # Accuracy\n",
    "print('Test Score',m1.score(x_test_cv,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0bddf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehul\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "pred_m1 = m1.predict(x_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5711095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR LOGISTIC REGRESSION :-\n",
      "Accuracy:  0.7981611208406305\n",
      "[[1137  181]\n",
      " [ 280  686]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83      1318\n",
      "           1       0.79      0.71      0.75       966\n",
      "\n",
      "    accuracy                           0.80      2284\n",
      "   macro avg       0.80      0.79      0.79      2284\n",
      "weighted avg       0.80      0.80      0.80      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR LOGISTIC REGRESSION :-\")\n",
    "eval_model(y_test,ypred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd349fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR Multinomial Naïve Bayes Classification  :-\n",
      "Accuracy:  0.7841506129597198\n",
      "[[1113  205]\n",
      " [ 288  678]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82      1318\n",
      "           1       0.77      0.70      0.73       966\n",
      "\n",
      "    accuracy                           0.78      2284\n",
      "   macro avg       0.78      0.77      0.78      2284\n",
      "weighted avg       0.78      0.78      0.78      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR Multinomial Naïve Bayes Classification  :-\")\n",
    "eval_model(y_test,ypred_mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aefc445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR KNN Classification :-\n",
      "Accuracy:  0.7092819614711033\n",
      "[[1226   92]\n",
      " [ 572  394]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79      1318\n",
      "           1       0.81      0.41      0.54       966\n",
      "\n",
      "    accuracy                           0.71      2284\n",
      "   macro avg       0.75      0.67      0.66      2284\n",
      "weighted avg       0.74      0.71      0.68      2284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"FOR KNN Classification :-\")\n",
    "eval_model(y_test,ypred_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330feae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
